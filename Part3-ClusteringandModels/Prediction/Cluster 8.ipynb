{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>...</th>\n",
       "      <th>localholiday</th>\n",
       "      <th>regionalholiday</th>\n",
       "      <th>nationalother</th>\n",
       "      <th>nholidayspike</th>\n",
       "      <th>goodfriday</th>\n",
       "      <th>blackfriday</th>\n",
       "      <th>worldcupspike</th>\n",
       "      <th>worldcupdrop</th>\n",
       "      <th>earthquakespike</th>\n",
       "      <th>earthquakedrop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>105.850000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3307.0</td>\n",
       "      <td>51.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>96.013333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>60.010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_sales  onpromotion  transactions  dcoilwtico  day_0  day_1  day_2  \\\n",
       "0         5.0            0         968.0  105.850000      0      0      0   \n",
       "1         4.0            0        3307.0   51.700000      0      0      0   \n",
       "2         3.0            1        1300.0   44.400000      1      0      0   \n",
       "3         6.0            0        1277.0   96.013333      0      0      0   \n",
       "4         5.0            0        1406.0   60.010000      0      0      1   \n",
       "\n",
       "   day_3  day_4  day_5       ...        localholiday  regionalholiday  \\\n",
       "0      0      1      0       ...                   0                0   \n",
       "1      0      1      0       ...                   0                0   \n",
       "2      0      0      0       ...                   0                0   \n",
       "3      0      0      1       ...                   0                0   \n",
       "4      0      0      0       ...                   0                0   \n",
       "\n",
       "   nationalother  nholidayspike  goodfriday  blackfriday  worldcupspike  \\\n",
       "0              0              0           0            0              0   \n",
       "1              0              0           0            0              0   \n",
       "2              0              0           0            0              0   \n",
       "3              0              0           0            0              0   \n",
       "4              0              0           0            0              0   \n",
       "\n",
       "   worldcupdrop  earthquakespike  earthquakedrop  \n",
       "0             0                0               0  \n",
       "1             0                0               0  \n",
       "2             0                0               0  \n",
       "3             0                0               0  \n",
       "4             0                0               0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_cluster8.csv', header=0, low_memory=False)\n",
    "data.dropna(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=data.values\n",
    "\n",
    "Y=array[:,0]\n",
    "X=array[:,1:]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.28522056073    |3.28369014909    |\n",
      "|mape   |109.630326372    |109.850182934    |\n"
     ]
    }
   ],
   "source": [
    "lm=LinearRegression()\n",
    "\n",
    "lm.fit(X_train, Y_train)\n",
    "\n",
    "ptrain = lm.predict(X_train)\n",
    "ptest = lm.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.28244152754    |3.28511109217    |\n",
      "|mape   |109.776033166    |109.607125584    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "lm.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = lm.predict(X_test)\n",
    "ptest = lm.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |2.35952368877    |3.68487322737    |\n",
      "|mape   |72.6510014626    |115.37451654    |\n"
     ]
    }
   ],
   "source": [
    "forest=RandomForestRegressor(n_estimators=100)\n",
    "forest.fit(X_train,Y_train)\n",
    "\n",
    "ptrain = forest.predict(X_train)\n",
    "ptest = forest.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |2.36020396183    |3.69197109301    |\n",
      "|mape   |73.0128215568    |115.621063992    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "forest=RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "forest.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = forest.predict(X_test)\n",
    "ptest = forest.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = int(sqrt(len(data.index)))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.28104476633    |3.28276344696    |\n",
      "|mape   |109.612610583    |109.954601594    |\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=k)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "ptrain = knn.predict(X_train)\n",
    "ptest = knn.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.27801050115    |3.28619014739    |\n",
      "|mape   |109.752268653    |109.734370524    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "knn = KNeighborsRegressor(n_neighbors=k)\n",
    "knn.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = knn.predict(X_test)\n",
    "ptest = knn.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.23851385852    |3.27717569879    |\n",
      "|mape   |105.969919064    |107.548627996    |\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train2 = scaler.transform(X_train)\n",
    "X_test2 = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train2,Y_train)\n",
    "ptrain = mlp.predict(X_train2)\n",
    "ptest = mlp.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.21637923317    |3.25847762333    |\n",
      "|mape   |104.808656098    |106.060457008    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_test2,Y_test)\n",
    "ptrain = mlp.predict(X_test2)\n",
    "ptest = mlp.predict(X_train2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.19170241492    |3.30543027578    |\n",
      "|mape   |104.770841963    |108.649816304    |\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(200,20,10))\n",
    "mlp.fit(X_train2,Y_train)\n",
    "ptrain = mlp.predict(X_train2)\n",
    "ptest = mlp.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.23694352826    |3.26208297136    |\n",
      "|mape   |105.580673438    |106.682626346    |\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(200,20,10), max_iter=20)\n",
    "mlp.fit(X_train2,Y_train)\n",
    "ptrain = mlp.predict(X_train2)\n",
    "ptest = mlp.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ['unit_sales','onpromotion','transactions','dcoilwtico','day_0','day_1','day_2',\n",
    "            'day_3','day_4','day_5','month_1','month_2','month_3','month_4','month_5',\n",
    "            'month_6','month_7','month_8','month_9','month_10','month_11','1013','1072',\n",
    "            'El Oro','Esmeraldas','Guayas','Imbabura','Los Rios','Manabi','Pichincha',\n",
    "            'Santa Elena','Santo Domingo de los Tsachilas','nationalother','nholidayspike',\n",
    "            'goodfriday','worldcupspike','worldcupdrop','earthquakespike','earthquakedrop']\n",
    "\n",
    "features = data[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2=features.values\n",
    "\n",
    "Y2=array2[:,0]\n",
    "X2=array2[:,1:]\n",
    "\n",
    "X_train2,X_test2,Y_train2,Y_test2=train_test_split(X2,Y2,test_size=0.5)\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(X_train2)\n",
    "X_train2 = scaler2.transform(X_train2)\n",
    "X_test2 = scaler2.transform(X_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.29221613579    |3.32592756521    |\n",
      "|mape   |110.898599759    |112.526595088    |\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train2,Y_train2)\n",
    "ptrain = mlp.predict(X_train2)\n",
    "ptest = mlp.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train2, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test2, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train2 - ptrain) / Y_train2)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test2 - ptest) / Y_test2)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=data.values\n",
    "\n",
    "Y=array[:,0]\n",
    "X=array[:,1:]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.5)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train2 = scaler.transform(X_train)\n",
    "X_test2 = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.28366835526    |3.32416722396    |\n",
      "|mape   |110.281690558    |111.464267792    |\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(200))\n",
    "mlp.fit(X_train2,Y_train)\n",
    "ptrain = mlp.predict(X_train2)\n",
    "ptest = mlp.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.30223444103    |3.304581317    |\n",
      "|mape   |116.79881519    |115.770517407    |\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(50), max_iter=100, learning_rate_init=.1, momentum=0)\n",
    "mlp.fit(X_train2,Y_train)\n",
    "ptrain = mlp.predict(X_train2)\n",
    "ptest = mlp.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.31056690101    |3.30829741454    |\n",
      "|mape   |116.170944248    |117.203192182    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50), max_iter=100, learning_rate_init=.1, momentum=0)\n",
    "mlp.fit(X_test2,Y_test)\n",
    "ptrain = mlp.predict(X_test2)\n",
    "ptest = mlp.predict(X_train2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ['unit_sales','onpromotion','transactions','dcoilwtico',\n",
    "            'day_0','day_1','day_2','day_3','day_4','day_5','month_1',\n",
    "            'month_2','month_3','month_4','month_5','month_6',\n",
    "            'month_7','month_8','month_9','month_10','month_11','1013','1072',\n",
    "            'El Oro','Esmeraldas','Guayas','Imbabura','Los Rios','Manabi',\n",
    "            'Pichincha','Santa Elena','Santo Domingo de los Tsachilas',\n",
    "            'nationalother','nholidayspike','goodfriday','worldcupspike',\n",
    "            'worldcupdrop','earthquakespike','earthquakedrop']\n",
    "\n",
    "features = data[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=features.values\n",
    "\n",
    "Y=array[:,0]\n",
    "X=array[:,1:]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.2773451317    |3.28432030772    |\n",
      "|mape   |109.722602109    |108.914027143    |\n"
     ]
    }
   ],
   "source": [
    "lm=LinearRegression()\n",
    "\n",
    "lm.fit(X_train, Y_train)\n",
    "\n",
    "ptrain = lm.predict(X_train)\n",
    "ptest = lm.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.29042863271    |3.28461465122    |\n",
      "|mape   |109.69343657    |110.538773332    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "lm.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = lm.predict(X_test)\n",
    "ptest = lm.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('train_cluster8_azure.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
