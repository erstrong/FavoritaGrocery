{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>...</th>\n",
       "      <th>localholiday</th>\n",
       "      <th>regionalholiday</th>\n",
       "      <th>nationalother</th>\n",
       "      <th>nholidayspike</th>\n",
       "      <th>goodfriday</th>\n",
       "      <th>blackfriday</th>\n",
       "      <th>worldcupspike</th>\n",
       "      <th>worldcupdrop</th>\n",
       "      <th>earthquakespike</th>\n",
       "      <th>earthquakedrop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3049.0</td>\n",
       "      <td>98.696667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5375.0</td>\n",
       "      <td>94.796667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>95.980000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>52.520000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_sales  onpromotion  transactions  dcoilwtico  day_0  day_1  day_2  \\\n",
       "0         2.0            0        3049.0   98.696667      0      0      0   \n",
       "1         1.0            0        1077.0   44.400000      1      0      0   \n",
       "2         3.0            0        5375.0   94.796667      0      0      0   \n",
       "3         6.0            0        1685.0   95.980000      0      0      1   \n",
       "4        12.0            0        1179.0   52.520000      0      0      0   \n",
       "\n",
       "   day_3  day_4  day_5       ...        localholiday  regionalholiday  \\\n",
       "0      0      0      0       ...                   0                0   \n",
       "1      0      0      0       ...                   0                0   \n",
       "2      0      0      0       ...                   0                0   \n",
       "3      0      0      0       ...                   0                0   \n",
       "4      0      0      1       ...                   0                0   \n",
       "\n",
       "   nationalother  nholidayspike  goodfriday  blackfriday  worldcupspike  \\\n",
       "0              0              0           0            0              0   \n",
       "1              0              0           0            0              0   \n",
       "2              0              0           0            0              0   \n",
       "3              0              0           0            0              0   \n",
       "4              0              0           0            0              0   \n",
       "\n",
       "   worldcupdrop  earthquakespike  earthquakedrop  \n",
       "0             0                0               0  \n",
       "1             0                0               0  \n",
       "2             0                0               0  \n",
       "3             0                0               0  \n",
       "4             0                0               0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_cluster7.csv', header=0, low_memory=False)\n",
    "data.dropna(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=data.values\n",
    "\n",
    "Y=array[:,0]\n",
    "X=array[:,1:]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |6.73416341233    |6.73520174937    |\n",
      "|mape   |153.053919285    |154.79421774    |\n"
     ]
    }
   ],
   "source": [
    "lm=LinearRegression()\n",
    "\n",
    "lm.fit(X_train, Y_train)\n",
    "\n",
    "ptrain = lm.predict(X_train)\n",
    "ptest = lm.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |6.70859144346    |6.73169151678    |\n",
      "|mape   |154.051176513    |152.720786161    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "lm.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = lm.predict(X_test)\n",
    "ptest = lm.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.38488607246    |7.30910181716    |\n",
      "|mape   |72.9528077276    |160.073276219    |\n"
     ]
    }
   ],
   "source": [
    "forest=RandomForestRegressor(n_estimators=100)\n",
    "forest.fit(X_train,Y_train)\n",
    "\n",
    "ptrain = forest.predict(X_train)\n",
    "ptest = forest.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.34099254442    |7.2994383484    |\n",
      "|mape   |71.7188570883    |158.57013536    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "forest=RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "forest.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = forest.predict(X_test)\n",
    "ptest = forest.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = int(sqrt(len(data.index)))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |6.76544124236    |6.76490596691    |\n",
      "|mape   |156.580793945    |158.328586821    |\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=k)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "ptrain = knn.predict(X_train)\n",
    "ptest = knn.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |6.73347562298    |6.7795997969    |\n",
      "|mape   |157.016378986    |156.198095938    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "knn = KNeighborsRegressor(n_neighbors=k)\n",
    "knn.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = knn.predict(X_test)\n",
    "ptest = knn.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |6.5275713301    |6.75285486922    |\n",
      "|mape   |146.109853228    |152.320125733    |\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train2 = scaler.transform(X_train)\n",
    "X_test2 = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train2,Y_train)\n",
    "ptrain = mlp.predict(X_train2)\n",
    "ptest = mlp.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |6.47798372188    |6.82109086352    |\n",
      "|mape   |144.992339277    |151.416139929    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_test2,Y_test)\n",
    "ptrain = mlp.predict(X_test2)\n",
    "ptest = mlp.predict(X_train2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected=['unit_sales','onpromotion','transactions','dcoilwtico','day_0','day_3','day_5',\n",
    "          'month_3','month_5','month_6','month_8','month_9','month_10','Azuay','Bolivar',\n",
    "          'Chimborazo','Cotopaxi','El Oro','Esmeraldas','Guayas','Imbabura','Los Rios',\n",
    "          'Manabi','Pastaza','Pichincha','Santa Elena','Santo Domingo de los Tsachilas',\n",
    "          'nholidayspike','blackfriday']\n",
    "\n",
    "features = data[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=features.values\n",
    "\n",
    "Y=array[:,0]\n",
    "X=array[:,1:]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |6.63864796334    |6.76466140948    |\n",
      "|mape   |152.91615438    |155.395302211    |\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train2 = scaler.transform(X_train)\n",
    "X_test2 = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(200), learning_rate='adaptive', max_iter=100)\n",
    "mlp.fit(X_train2,Y_train)\n",
    "ptrain = mlp.predict(X_train2)\n",
    "ptest = mlp.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |6.42704271499    |6.84224828575    |\n",
      "|mape   |145.482479538    |153.437071101    |\n"
     ]
    }
   ],
   "source": [
    "array=data.values\n",
    "\n",
    "Y=array[:,0]\n",
    "X=array[:,1:]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.5)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train2 = scaler.transform(X_train)\n",
    "X_test2 = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(500))\n",
    "mlp.fit(X_train2,Y_train)\n",
    "ptrain = mlp.predict(X_train2)\n",
    "ptest = mlp.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |6.23367362334    |6.79728749307    |\n",
      "|mape   |133.9444643    |144.814422068    |\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(500,20,10))\n",
    "mlp.fit(X_train2,Y_train)\n",
    "ptrain = mlp.predict(X_train2)\n",
    "ptest = mlp.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |6.29195273343    |6.91028090922    |\n",
      "|mape   |141.259393524    |156.342216126    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(500,20,10))\n",
    "mlp.fit(X_test2,Y_test)\n",
    "ptrain = mlp.predict(X_test2)\n",
    "ptest = mlp.predict(X_train2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('train_cluster7_azure.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
