{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>...</th>\n",
       "      <th>localholiday</th>\n",
       "      <th>regionalholiday</th>\n",
       "      <th>nationalother</th>\n",
       "      <th>nholidayspike</th>\n",
       "      <th>goodfriday</th>\n",
       "      <th>blackfriday</th>\n",
       "      <th>worldcupspike</th>\n",
       "      <th>worldcupdrop</th>\n",
       "      <th>earthquakespike</th>\n",
       "      <th>earthquakedrop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>92.470000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>88.730000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>104.330000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>94.573333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1753.0</td>\n",
       "      <td>95.350000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_sales  onpromotion  transactions  dcoilwtico  day_0  day_1  day_2  \\\n",
       "0         3.0            0        1317.0   92.470000      0      0      1   \n",
       "1        10.0            0         932.0   88.730000      0      1      0   \n",
       "2         1.0            0        1784.0  104.330000      0      0      0   \n",
       "3        14.0            0        1200.0   94.573333      0      0      0   \n",
       "4         1.0            0        1753.0   95.350000      0      0      0   \n",
       "\n",
       "   day_3  day_4  day_5       ...        localholiday  regionalholiday  \\\n",
       "0      0      0      0       ...                   0                0   \n",
       "1      0      0      0       ...                   0                0   \n",
       "2      1      0      0       ...                   0                0   \n",
       "3      0      0      0       ...                   0                0   \n",
       "4      1      0      0       ...                   0                0   \n",
       "\n",
       "   nationalother  nholidayspike  goodfriday  blackfriday  worldcupspike  \\\n",
       "0              0              0           0            0              0   \n",
       "1              0              0           0            0              0   \n",
       "2              0              0           0            0              0   \n",
       "3              0              1           0            0              0   \n",
       "4              0              0           0            0              0   \n",
       "\n",
       "   worldcupdrop  earthquakespike  earthquakedrop  \n",
       "0             0                0               0  \n",
       "1             0                0               0  \n",
       "2             0                0               0  \n",
       "3             0                0               0  \n",
       "4             0                0               0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_cluster3.csv', header=0, low_memory=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=data.values\n",
    "\n",
    "Y=array[:,0]\n",
    "X=array[:,1:]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.69877857453    |3.69564205273    |\n",
      "|mape   |118.355929414    |118.107319756    |\n"
     ]
    }
   ],
   "source": [
    "lm=LinearRegression()\n",
    "\n",
    "lm.fit(X_train, Y_train)\n",
    "\n",
    "ptrain = lm.predict(X_train)\n",
    "ptest = lm.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.69377823031    |3.6993573669    |\n",
      "|mape   |118.037847503    |118.388289814    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "lm.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = lm.predict(X_test)\n",
    "ptest = lm.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |2.39717807681    |4.17500340351    |\n",
      "|mape   |70.4129640538    |124.592471277    |\n"
     ]
    }
   ],
   "source": [
    "forest=RandomForestRegressor(n_estimators=100)\n",
    "forest.fit(X_train,Y_train)\n",
    "\n",
    "ptrain = forest.predict(X_train)\n",
    "ptest = forest.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |2.39898309697    |4.17459238559    |\n",
      "|mape   |70.3133271393    |125.2354524    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "forest=RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "forest.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = forest.predict(X_test)\n",
    "ptest = forest.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = int(sqrt(len(data.index)))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.69478561805    |3.70250792262    |\n",
      "|mape   |118.955741999    |118.898165942    |\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=k)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "ptrain = knn.predict(X_train)\n",
    "ptest = knn.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.6938135909    |3.70269309369    |\n",
      "|mape   |118.525019214    |119.082422987    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "knn = KNeighborsRegressor(n_neighbors=k)\n",
    "knn.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = knn.predict(X_test)\n",
    "ptest = knn.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |4.9311429106    |5.03001580521    |\n",
      "|mape   |129.722023831    |131.833158508    |\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train2 = scaler.transform(X_train)\n",
    "X_test2 = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train2,Y_train)\n",
    "ptrain = mlp.predict(X_train2)\n",
    "ptest = mlp.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |4.86377244088    |4.95278559711    |\n",
      "|mape   |125.038205439    |127.790042866    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_test2,Y_test)\n",
    "ptrain = mlp.predict(X_test2)\n",
    "ptest = mlp.predict(X_train2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.73024403713    |3.73013902322    |\n",
      "|mape   |122.301253719    |121.993220591    |\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "model=LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=20)\n",
    "rfe.fit(X_train,Y_train)\n",
    "\n",
    "ptrain = rfe.predict(X_train)\n",
    "ptest = rfe.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected=['unit_sales','onpromotion','transactions','dcoilwtico',\n",
    "          'day_0','day_1','day_2','day_3','day_4','day_5','month_1',\n",
    "          'month_2','month_3','month_4','month_6','month_7','month_8',\n",
    "          'month_9','month_10','month_11','Azuay','Bolivar',\n",
    "          'Chimborazo','Cotopaxi','El Oro','Esmeraldas','Guayas',\n",
    "          'Imbabura','Loja','Los Rios','Manabi','Pastaza','Pichincha',\n",
    "          'Santa Elena','Santo Domingo de los Tsachilas',\n",
    "          'regionalholiday','nationalother','nholidayspike',\n",
    "          'goodfriday','blackfriday','worldcupspike']\n",
    "features = data[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=features.values\n",
    "\n",
    "Y=array[:,0]\n",
    "X=array[:,1:]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.6988468892    |3.69777795748    |\n",
      "|mape   |118.102237856    |118.606646727    |\n"
     ]
    }
   ],
   "source": [
    "lm=LinearRegression()\n",
    "\n",
    "lm.fit(X_train, Y_train)\n",
    "\n",
    "ptrain = lm.predict(X_train)\n",
    "ptest = lm.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |3.69341279574    |3.69702355808    |\n",
      "|mape   |118.275451152    |117.856044895    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "lm.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = lm.predict(X_test)\n",
    "ptest = lm.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('train_cluster3_azure.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
