{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>...</th>\n",
       "      <th>localholiday</th>\n",
       "      <th>regionalholiday</th>\n",
       "      <th>nationalother</th>\n",
       "      <th>nholidayspike</th>\n",
       "      <th>goodfriday</th>\n",
       "      <th>blackfriday</th>\n",
       "      <th>worldcupspike</th>\n",
       "      <th>worldcupdrop</th>\n",
       "      <th>earthquakespike</th>\n",
       "      <th>earthquakedrop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>44.390000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>94.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2332.0</td>\n",
       "      <td>35.910000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>45.303333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4310.0</td>\n",
       "      <td>50.050000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_sales  onpromotion  transactions  dcoilwtico  day_0  day_1  day_2  \\\n",
       "0         6.0            0         952.0   44.390000      0      0      0   \n",
       "1         1.0            0         702.0   94.750000      0      0      0   \n",
       "2         7.0            0        2332.0   35.910000      0      0      0   \n",
       "3         7.0            0        1620.0   45.303333      0      0      0   \n",
       "4         4.0            0        4310.0   50.050000      1      0      0   \n",
       "\n",
       "   day_3  day_4  day_5       ...        localholiday  regionalholiday  \\\n",
       "0      0      1      0       ...                   0                0   \n",
       "1      0      0      1       ...                   0                0   \n",
       "2      0      1      0       ...                   0                0   \n",
       "3      0      0      0       ...                   0                0   \n",
       "4      0      0      0       ...                   0                0   \n",
       "\n",
       "   nationalother  nholidayspike  goodfriday  blackfriday  worldcupspike  \\\n",
       "0              0              0           0            0              0   \n",
       "1              0              0           0            0              0   \n",
       "2              0              0           0            0              0   \n",
       "3              0              0           0            0              0   \n",
       "4              0              0           0            0              0   \n",
       "\n",
       "   worldcupdrop  earthquakespike  earthquakedrop  \n",
       "0             0                0               0  \n",
       "1             0                0               0  \n",
       "2             0                0               0  \n",
       "3             0                0               0  \n",
       "4             0                0               0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_cluster4.csv', header=0, low_memory=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=data.values\n",
    "\n",
    "Y=array[:,0]\n",
    "X=array[:,1:]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |1.60452993812    |1.60753634475    |\n",
      "|mape   |75.6795277545    |75.8338208977    |\n"
     ]
    }
   ],
   "source": [
    "lm=LinearRegression()\n",
    "\n",
    "lm.fit(X_train, Y_train)\n",
    "\n",
    "ptrain = lm.predict(X_train)\n",
    "ptest = lm.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |1.60777786903    |1.60563785684    |\n",
      "|mape   |75.8335080017    |75.722762408    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "lm.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = lm.predict(X_test)\n",
    "ptest = lm.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |0.738743157124    |1.70469996145    |\n",
      "|mape   |33.7362902051    |78.8860623088    |\n"
     ]
    }
   ],
   "source": [
    "forest=RandomForestRegressor(n_estimators=100)\n",
    "forest.fit(X_train,Y_train)\n",
    "\n",
    "ptrain = forest.predict(X_train)\n",
    "ptest = forest.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |0.7391441518    |1.70487898669    |\n",
      "|mape   |33.7852952417    |78.8446059127    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "forest=RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "forest.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = forest.predict(X_test)\n",
    "ptest = forest.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = int(sqrt(len(data.index)))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |1.60229017465    |1.60715162962    |\n",
      "|mape   |75.6890523276    |75.9029048664    |\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=k)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "ptrain = knn.predict(X_train)\n",
    "ptest = knn.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |1.60567745642    |1.60544399243    |\n",
      "|mape   |75.7771465241    |75.7772003433    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "knn = KNeighborsRegressor(n_neighbors=k)\n",
    "knn.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = knn.predict(X_test)\n",
    "ptest = knn.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |1.59689036649    |1.63903255609    |\n",
      "|mape   |76.6660479889    |78.6896245272    |\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train2 = scaler.transform(X_train)\n",
    "X_test2 = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train2,Y_train)\n",
    "ptrain = mlp.predict(X_train2)\n",
    "ptest = mlp.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |1.57124687876    |1.60884851009    |\n",
      "|mape   |73.3567182632    |75.1654819134    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_test2,Y_test)\n",
    "ptrain = mlp.predict(X_test2)\n",
    "ptest = mlp.predict(X_train2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |1.61660527626    |1.62091060611    |\n",
      "|mape   |78.1119092572    |78.272355584    |\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "model=LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=20)\n",
    "rfe.fit(X_train,Y_train)\n",
    "\n",
    "ptrain = rfe.predict(X_train)\n",
    "ptest = rfe.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ['unit_sales','onpromotion','transactions','dcoilwtico','day_0','day_1','day_2','day_3',\n",
    "            'day_4','month_1','month_2','month_3','month_4','month_5','month_6','month_7','month_8',\n",
    "            'month_9','month_10','month_11','1025','1028','1032','1036','1038','1039','1044',\n",
    "            '1048','1054','1056','1078','1086','1092','Azuay','Bolivar','Cotopaxi','El Oro',\n",
    "            'Esmeraldas','Guayas','Imbabura','Los Rios','Manabi','Pastaza',\n",
    "            'Santa Elena','Santo Domingo de los Tsachilas','nationalother','nholidayspike',\n",
    "            'earthquakespike']\n",
    "\n",
    "features = data[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2=features.values\n",
    "\n",
    "Y2=array2[:,0]\n",
    "X2=array2[:,1:]\n",
    "\n",
    "X_train2,X_test2,Y_train2,Y_test2=train_test_split(X2,Y2,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |1.60600070638    |1.60631672702    |\n",
      "|mape   |75.7493212752    |75.8171441317    |\n"
     ]
    }
   ],
   "source": [
    "lm=LinearRegression()\n",
    "\n",
    "lm.fit(X_train2, Y_train2)\n",
    "\n",
    "ptrain = lm.predict(X_train2)\n",
    "ptest = lm.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train2, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test2, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train2 - ptrain) / Y_train2)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test2 - ptest) / Y_test2)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |1.60631141386    |1.60650195221    |\n",
      "|mape   |75.7705966149    |75.7257286507    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "lm.fit(X_test2, Y_test2)\n",
    "\n",
    "ptrain = lm.predict(X_test2)\n",
    "ptest = lm.predict(X_train2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test2, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train2, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test2 - ptrain) / Y_test2)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train2 - ptest) / Y_train2)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('train_cluster4_azure.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
