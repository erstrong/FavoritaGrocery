{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>...</th>\n",
       "      <th>localholiday</th>\n",
       "      <th>regionalholiday</th>\n",
       "      <th>nationalother</th>\n",
       "      <th>nholidayspike</th>\n",
       "      <th>goodfriday</th>\n",
       "      <th>blackfriday</th>\n",
       "      <th>worldcupspike</th>\n",
       "      <th>worldcupdrop</th>\n",
       "      <th>earthquakespike</th>\n",
       "      <th>earthquakedrop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3005.0</td>\n",
       "      <td>40.895000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5523.0</td>\n",
       "      <td>82.786667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1631.0</td>\n",
       "      <td>48.830000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>99.280000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2068.0</td>\n",
       "      <td>106.830000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_sales  onpromotion  transactions  dcoilwtico  day_0  day_1  day_2  \\\n",
       "0         1.0            0        3005.0   40.895000      0      0      0   \n",
       "1         1.0            0        5523.0   82.786667      0      0      0   \n",
       "2         1.0            0        1631.0   48.830000      0      0      0   \n",
       "3         1.0            0        2650.0   99.280000      1      0      0   \n",
       "4         1.0            0        2068.0  106.830000      0      0      0   \n",
       "\n",
       "   day_3  day_4  day_5       ...        localholiday  regionalholiday  \\\n",
       "0      1      0      0       ...                   0                0   \n",
       "1      0      0      1       ...                   0                0   \n",
       "2      0      1      0       ...                   0                0   \n",
       "3      0      0      0       ...                   0                0   \n",
       "4      0      0      1       ...                   0                0   \n",
       "\n",
       "   nationalother  nholidayspike  goodfriday  blackfriday  worldcupspike  \\\n",
       "0              0              0           0            0              0   \n",
       "1              0              0           0            0              0   \n",
       "2              0              0           0            0              0   \n",
       "3              0              0           0            0              0   \n",
       "4              0              0           0            0              0   \n",
       "\n",
       "   worldcupdrop  earthquakespike  earthquakedrop  \n",
       "0             0                0               0  \n",
       "1             0                0               0  \n",
       "2             0                0               0  \n",
       "3             0                0               0  \n",
       "4             0                0               0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_cluster5.csv', header=0, low_memory=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=data.values\n",
    "\n",
    "Y=array[:,0]\n",
    "X=array[:,1:]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |0.522646305249    |0.534347661827    |\n",
      "|mape   |36.9559092456    |37.3638001872    |\n"
     ]
    }
   ],
   "source": [
    "lm=LinearRegression()\n",
    "\n",
    "lm.fit(X_train, Y_train)\n",
    "\n",
    "ptrain = lm.predict(X_train)\n",
    "ptest = lm.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |0.537838464764    |0.535620299674    |\n",
      "|mape   |38.05241166    |38.3393356977    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "lm.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = lm.predict(X_test)\n",
    "ptest = lm.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |0.195884302837    |0.532138591231    |\n",
      "|mape   |14.0633641847    |37.7087817476    |\n"
     ]
    }
   ],
   "source": [
    "forest=RandomForestRegressor(n_estimators=100)\n",
    "forest.fit(X_train,Y_train)\n",
    "\n",
    "ptrain = forest.predict(X_train)\n",
    "ptest = forest.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |0.203279958544    |0.539006897589    |\n",
      "|mape   |14.6364186778    |39.355409783    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "forest=RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "forest.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = forest.predict(X_test)\n",
    "ptest = forest.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = int(sqrt(len(data.index)))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |0.529245927508    |0.538909390356    |\n",
      "|mape   |37.2900409574    |37.5124580083    |\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=k)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "ptrain = knn.predict(X_train)\n",
    "ptest = knn.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |0.541372131772    |0.540372754477    |\n",
      "|mape   |38.184260517    |38.5354424655    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "knn = KNeighborsRegressor(n_neighbors=k)\n",
    "knn.fit(X_test, Y_test)\n",
    "\n",
    "ptrain = knn.predict(X_test)\n",
    "ptest = knn.predict(X_train)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |0.359604722829    |0.586569655799    |\n",
      "|mape   |25.7856794848    |41.88039886    |\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train2 = scaler.transform(X_train)\n",
    "X_test2 = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_train2,Y_train)\n",
    "ptrain = mlp.predict(X_train2)\n",
    "ptest = mlp.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |0.408985196117    |0.577574435157    |\n",
      "|mape   |29.7887270033    |42.4545084772    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50,20,10))\n",
    "mlp.fit(X_test2,Y_test)\n",
    "ptrain = mlp.predict(X_test2)\n",
    "ptest = mlp.predict(X_train2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test - ptrain) / Y_test)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train - ptest) / Y_train)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |0.528494366497    |0.536626217572    |\n",
      "|mape   |37.308028122    |37.4647658173    |\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "model=LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=25)\n",
    "rfe.fit(X_train,Y_train)\n",
    "\n",
    "ptrain = rfe.predict(X_train)\n",
    "ptest = rfe.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train - ptrain) / Y_train)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test - ptest) / Y_test)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected=['unit_sales','transactions','dcoilwtico','day_4','day_5','month_7',\n",
    "          '1018','1029','1033','1041','Pichincha',\n",
    "          'Santo Domingo de los Tsachilas','nationalother',\n",
    "          'nholidayspike','worldcupdrop']\n",
    "\n",
    "features = data[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2=features.values\n",
    "\n",
    "Y2=array2[:,0]\n",
    "X2=array2[:,1:]\n",
    "\n",
    "X_train2,X_test2,Y_train2,Y_test2=train_test_split(X2,Y2,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |0.538622531977    |0.532172068532    |\n",
      "|mape   |38.0694741325    |37.9295483283    |\n"
     ]
    }
   ],
   "source": [
    "lm=LinearRegression()\n",
    "\n",
    "lm.fit(X_train2, Y_train2)\n",
    "\n",
    "ptrain = lm.predict(X_train2)\n",
    "ptest = lm.predict(X_test2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_train2, ptrain)\n",
    "mae_test = mean_absolute_error(Y_test2, ptest)\n",
    "mape_train = np.mean(np.abs((Y_train2 - ptrain) / Y_train2)) * 100\n",
    "mape_test = np.mean(np.abs((Y_test2 - ptest) / Y_test2)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|metric |train            |test             | \n",
      "|mae    |0.526229836991    |0.535527237801    |\n",
      "|mape   |37.2447422718    |37.5322677938    |\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "lm.fit(X_test2, Y_test2)\n",
    "\n",
    "ptrain = lm.predict(X_test2)\n",
    "ptest = lm.predict(X_train2)\n",
    "\n",
    "mae_train = mean_absolute_error(Y_test2, ptrain)\n",
    "mae_test = mean_absolute_error(Y_train2, ptest)\n",
    "mape_train = np.mean(np.abs((Y_test2 - ptrain) / Y_test2)) * 100\n",
    "mape_test = np.mean(np.abs((Y_train2 - ptest) / Y_train2)) * 100\n",
    "\n",
    "print('|metric |train            |test             | \\n|mae    |' +str(mae_train)\n",
    "      +'    |'+str(mae_test)+'    |\\n|mape   |'+str(mape_train)+'    |'+str(mape_test)\n",
    "      +'    |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('train_cluster5_azure.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
